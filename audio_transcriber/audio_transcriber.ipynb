{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb4f05f-9237-4a9c-b661-37c9539df091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import transcription_utils as utils\n",
    "import warnings\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6a0e52-37a9-4df0-a954-c50a4afc287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Disable SSL warnings (optional but not recommended in production)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd13e31a-2f4f-48e9-aa84-4d7351a816be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ§ Using audio file: ./resources/input\\audio_sample.mp3\n",
      "ðŸ§  Transcribing with Whisper (spanish)... please wait, this can take several minutes...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Model spanish not found; available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large', 'large-v3-turbo', 'turbo']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m MODEL_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# You can use tiny, base, small, medium, large\u001b[39;00m\n\u001b[0;32m      5\u001b[0m LANGUAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspanish\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAUDIO_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLANGUAGE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m display(Markdown(summary))\n",
      "File \u001b[1;32m~\\MIS_COSAS\\git_repos\\ai_development_toolkit\\audio_transcriber\\utils\\transcription_utils.py:43\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_dir, output_dir, language, model_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# 4. Load the Whisper model and transcribe\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ§  Transcribing with Whisper (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)... please wait, this can take several minutes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio_path)\n\u001b[0;32m     46\u001b[0m transcription \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\dev_toolkit\\Lib\\site-packages\\whisper\\__init__.py:143\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[0;32m    141\u001b[0m     alignment_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found; available models = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_models()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m     )\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[0;32m    148\u001b[0m     io\u001b[38;5;241m.\u001b[39mBytesIO(checkpoint_file) \u001b[38;5;28;01mif\u001b[39;00m in_memory \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    150\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(fp, map_location\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Model spanish not found; available models = ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large', 'large-v3-turbo', 'turbo']"
     ]
    }
   ],
   "source": [
    "# 1. Settings\n",
    "AUDIO_DIR = \"./resources/input/\"\n",
    "OUTPUT_DIR = \"./resources/output/\"\n",
    "MODEL_SIZE = \"medium\"  # You can use tiny, base, small, medium, large\n",
    "LANGUAGE = \"spanish\"\n",
    "\n",
    "summary = utils.transcribe_audio(AUDIO_DIR, OUTPUT_DIR, MODEL_SIZE, LANGUAGE)\n",
    "\n",
    "display(Markdown(summary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
