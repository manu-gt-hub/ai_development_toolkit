{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc15b65-9f04-4f79-8516-2831835cac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS:\n",
    "# preguntas sugeridas para candidato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bc5a6-669c-4de4-9c32-17aef875d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.cv_reviewer_utils as cv_utils\n",
    "from IPython.display import Markdown, display\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3430549e-7dd9-4de9-8d28-ea5163613c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if its published somewhere\n",
    "#job_description = get_job_description(\"url\")\n",
    "\n",
    "job_description = \"\"\"\n",
    "\n",
    "Job Title: Junior Data Engineer\n",
    "Location: Remote\n",
    "Job Type: Full-time\n",
    "Team: Data Engineering\n",
    "Reports to: Senior Data Engineer\n",
    "\n",
    "About the Role:\n",
    "\n",
    "We are looking for a Junior Data Engineer to join our growing data team. You will support the design, development, and maintenance of data pipelines and infrastructure that power data analytics, reporting, and data-driven decision-making across the company.\n",
    "This is a great opportunity for someone early in their career to learn and grow while working on real-world data challenges in a collaborative and agile environment.\n",
    "\n",
    "Key Responsibilities\n",
    "- Assist in building, maintaining, and optimizing ETL/ELT pipelines.\n",
    "- Work closely with data analysts, scientists, and engineers to support data ingestion and transformation workflows.\n",
    "- Help ensure the reliability and quality of data across systems.\n",
    "- Monitor and troubleshoot data pipelines and processes.\n",
    "- Contribute to documentation of data flows, models, and architecture.\n",
    "- Learn and apply best practices in data engineering, including security and scalability.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Basic knowledge of SQL and at least one programming language (Python preferred).\n",
    "- Familiarity with data storage systems (e.g., relational databases, cloud storage).\n",
    "- Understanding of data processing concepts and tools.\n",
    "- Willingness to learn and grow in a fast-paced environment.\n",
    "- Good communication and problem-solving skills.\n",
    "- Bachelorâ€™s degree in Computer Science, Engineering, Mathematics, or related field (or equivalent practical experience).\n",
    "\n",
    "Nice to Have:\n",
    "\n",
    "- Exposure to cloud platforms like AWS, GCP, or Azure.\n",
    "- Experience with version control (e.g., Git).\n",
    "- Basic knowledge of data modeling concepts.\n",
    "- Familiarity with tools like Airflow, dbt, or Spark.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# in lower case\n",
    "mandatory_keywrods = [\"spark\",\"python\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c8a86d-f790-44da-9a1e-3e3e1862d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ Using llama3.2 via Ollama...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Data Engineer B.A.', 'match_percentage': 60, 'summary': 'The candidate has a strong background in data engineering with experience in Spark, Python, and AWS. However, the seniority does not match the job description as they are currently working as Data Engineers and do not mention junior or any lower position.'}\n",
      "â–¶ï¸ Using llama3.2 via Ollama...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Anonymized CV Holder', 'match_percentage': 50, 'summary': 'Lacks seniority and cloud experience, has some relevant skills like Spark, Python, and database systems. Gaps in security and scalability knowledge.'}\n",
      "â–¶ï¸ Using llama3.2 via Ollama...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Anonymous Data Engineer', 'match_percentage': 32, 'summary': 'Although the candidate has experience with large datasets and some programming languages (Java, Python), their seniority and match to the Junior Data Engineer role are limited. The candidate lacks direct experience with ETL/ELT pipelines, data storage systems, and cloud platforms, which are essential for the job. They also lack knowledge of tools like Airflow, dbt, or Spark, which is a nice-to-have requirement.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ï¸ Using llama3.2 via Ollama...\n",
      "{'name': 'Thaddeus', 'match_percentage': 70, 'summary': 'Strong knowledge in AWS, Python and MySQL. Experience with data pipelines on Airflow and ETL workflows using Apache NiFi. However, lacks experience with Spark and cloud platforms like GCP or Azure.'}\n"
     ]
    }
   ],
   "source": [
    "landing_path = './landing'\n",
    "        \n",
    "# \"llama3.2\" or chatgpt model\n",
    "model = \"llama3.2\"\n",
    "\n",
    "descriptions_dict = {}\n",
    "evaluation_dict = {}\n",
    "matches = []\n",
    "\n",
    "for filename in os.listdir(landing_path):\n",
    "    path = os.path.join(landing_path, filename)\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        cv_text = cv_utils.extract_text_from_cv(path)\n",
    "        if cv_text is not None:\n",
    "            \n",
    "            words = cv_text.split()    \n",
    "            num_of_words = len(words)\n",
    "\n",
    "            if num_of_words > 5:    \n",
    "                anonymized_desc = cv_utils.anonymize_resume(cv_text)\n",
    "\n",
    "                # keywords string is not mandatory\n",
    "                keywords_string = \"Additional note: \" + cv_utils.evaluate_mandatory_keywords(anonymized_desc,mandatory_keywrods)\n",
    "\n",
    "                llm_answer = cv_utils.evaluate_candidate(model, anonymized_desc, job_description, keywords_string)\n",
    "\n",
    "                print(llm_answer)\n",
    "                llm_answer['name'] = filename\n",
    "\n",
    "                updated_json_str = json.dumps(llm_answer, indent=2)\n",
    "\n",
    "                matches.append(updated_json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7938c4f-47d6-4e6f-958c-03f0e3d1621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### ğŸ“Š Candidate Evaluations\n",
       "\n",
       "**ğŸ§‘â€ğŸ’¼ Candidate nÂº1: Thaddeus Drake.pdf â€“ 70%**\n",
       "\n",
       "    Strong knowledge in AWS, Python and MySQL. Experience with data pipelines on Airflow and ETL workflows using Apache NiFi. However, lacks experience with Spark and cloud platforms like GCP or Azure.\n",
       "    \n",
       "**ğŸ§‘â€ğŸ’¼ Candidate nÂº2: alan susa.pdf â€“ 60%**\n",
       "\n",
       "    The candidate has a strong background in data engineering with experience in Spark, Python, and AWS. However, the seniority does not match the job description as they are currently working as Data Engineers and do not mention junior or any lower position.\n",
       "    \n",
       "**ğŸ§‘â€ğŸ’¼ Candidate nÂº3: Elara Quinn.pdf â€“ 50%**\n",
       "\n",
       "    Lacks seniority and cloud experience, has some relevant skills like Spark, Python, and database systems. Gaps in security and scalability knowledge.\n",
       "    \n",
       "**ğŸ§‘â€ğŸ’¼ Candidate nÂº4: john smith.pdf â€“ 32%**\n",
       "\n",
       "    Although the candidate has experience with large datasets and some programming languages (Java, Python), their seniority and match to the Junior Data Engineer role are limited. The candidate lacks direct experience with ETL/ELT pipelines, data storage systems, and cloud platforms, which are essential for the job. They also lack knowledge of tools like Airflow, dbt, or Spark, which is a nice-to-have requirement.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convierte elementos si son strings\n",
    "parsed_matches = [json.loads(m) if isinstance(m, str) else m for m in matches]\n",
    "\n",
    "# Ahora puedes ordenarlos sin error\n",
    "sorted_matches = sorted(parsed_matches, key=lambda x: x['match_percentage'], reverse=True)\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "### ğŸ“Š Candidate Evaluations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "n = 1\n",
    "for match in sorted_matches:\n",
    "    markdown_text += f\"\"\"**ğŸ§‘â€ğŸ’¼ Candidate nÂº{n}: {match['name']} â€“ {match['match_percentage']}%**\n",
    "\n",
    "    {match['summary']}\n",
    "    \n",
    "\"\"\"\n",
    "    n+=1\n",
    "\n",
    "display(Markdown(markdown_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
