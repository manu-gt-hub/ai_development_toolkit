{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bc5a6-669c-4de4-9c32-17aef875d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.cv_reviewer_utils as cv_utils\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3430549e-7dd9-4de9-8d28-ea5163613c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if its published somewhere\n",
    "#job_description = get_job_description(\"url\")\n",
    "\n",
    "job_description = \"\"\"\n",
    "\n",
    "Job Title: Junior Data Engineer\n",
    "Location: Remote\n",
    "Job Type: Full-time\n",
    "Team: Data Engineering\n",
    "Reports to: Senior Data Engineer\n",
    "\n",
    "About the Role:\n",
    "\n",
    "We are looking for a Junior Data Engineer to join our growing data team. You will support the design, development, and maintenance of data pipelines and infrastructure that power data analytics, reporting, and data-driven decision-making across the company.\n",
    "This is a great opportunity for someone early in their career to learn and grow while working on real-world data challenges in a collaborative and agile environment.\n",
    "\n",
    "Key Responsibilities\n",
    "- Assist in building, maintaining, and optimizing ETL/ELT pipelines.\n",
    "- Work closely with data analysts, scientists, and engineers to support data ingestion and transformation workflows.\n",
    "- Help ensure the reliability and quality of data across systems.\n",
    "- Monitor and troubleshoot data pipelines and processes.\n",
    "- Contribute to documentation of data flows, models, and architecture.\n",
    "- Learn and apply best practices in data engineering, including security and scalability.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Basic knowledge of SQL and at least one programming language (Python preferred).\n",
    "- Familiarity with data storage systems (e.g., relational databases, cloud storage).\n",
    "- Understanding of data processing concepts and tools.\n",
    "- Willingness to learn and grow in a fast-paced environment.\n",
    "- Good communication and problem-solving skills.\n",
    "- Bachelor’s degree in Computer Science, Engineering, Mathematics, or related field (or equivalent practical experience).\n",
    "\n",
    "Nice to Have:\n",
    "\n",
    "- Exposure to cloud platforms like AWS, GCP, or Azure.\n",
    "- Experience with version control (e.g., Git).\n",
    "- Basic knowledge of data modeling concepts.\n",
    "- Familiarity with tools like Airflow, dbt, or Spark.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# in lower case\n",
    "mandatory_keywrods = [\"spark\",\"python\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c8a86d-f790-44da-9a1e-3e3e1862d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Using gpt-4-turbo via OpenAI API...\n",
      "▶️ Using gpt-4-turbo via OpenAI API...\n",
      "▶️ Using gpt-4-turbo via OpenAI API...\n",
      "▶️ Using gpt-4-turbo via OpenAI API...\n"
     ]
    }
   ],
   "source": [
    "landing_path = './landing'\n",
    "\n",
    "descriptions_dict = {}\n",
    "evaluation_dict = {}\n",
    "matches = []\n",
    "\n",
    "for filename in os.listdir(landing_path):\n",
    "    path = os.path.join(landing_path, filename)\n",
    "    \n",
    "    if os.path.isfile(path):\n",
    "        cv_text = cv_utils.extract_text_from_cv(path)\n",
    "        if cv_text is not None:\n",
    "            \n",
    "            words = cv_text.split()    \n",
    "            num_of_words = len(words)\n",
    "\n",
    "            if num_of_words > 5:    \n",
    "                descriptions_dict[filename] = cv_text\n",
    "\n",
    "for filename,candidate_desc in descriptions_dict.items():\n",
    "\n",
    "        # \"llama3.2\" or chatgpt model\n",
    "        model = \"gpt-4-turbo\"\n",
    "\n",
    "        # keywords string is not mandatory\n",
    "        keywords_string = \"Additional note: \" + cv_utils.evaluate_mandatory_keywords(candidate_desc,mandatory_keywrods)\n",
    "    \n",
    "        llm_answer = cv_utils.evaluate_candidate(model, candidate_desc, job_description, keywords_string)\n",
    "        matches.append(llm_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7938c4f-47d6-4e6f-958c-03f0e3d1621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### 📊 Candidate Evaluations\n",
       "\n",
       "**🧑‍💼 Candidate nº1: Thaddeus Drake – 85%**\n",
       "\n",
       "    Thaddeus has demonstrated strong capabilities in data engineering, particularly with technologies such as AWS, Apache NiFi, and Apache Airflow, which align well with the job requirements. He has experience in building and optimizing ETL processes, a core requirement for the role. His use of Python and SQL, along with his familiarity with cloud platforms and version control using Git, positions him well for the Junior Data Engineer role. However, there is no mention of experience with GCP, Azure, or specific data modeling concepts, which are listed as nice to have.\n",
       "    \n",
       "**🧑‍💼 Candidate nº2: Elara Quinn – 65%**\n",
       "\n",
       "    Elara has relevant experience as a Data Engineer Intern, working with data pipelines, MySQL, and AWS, which aligns well with the junior role. However, there is no mention of Python, which is preferred, and tools like Airflow or Spark are not listed. Her experience with AWS and data processing tools like Apache NiFi and Hadoop supports the job requirements, but gaps in specific programming skills and some tools could be a limitation.\n",
       "    \n",
       "**🧑‍💼 Candidate nº3: John Smith – 55%**\n",
       "\n",
       "    John Smith has extensive experience in data engineering, including working with SQL, Python, Spark, and ETL processes, which aligns well with the technical requirements of the role. However, his seniority level as a seasoned data engineer with over 5 years of experience and significant responsibilities in previous roles suggests he is overqualified for a junior position. This mismatch in seniority and the potential underutilization of his skills could affect his fit for the junior role advertised.\n",
       "    \n",
       "**🧑‍💼 Candidate nº4: ALAN SUSA – 45%**\n",
       "\n",
       "    Alan has extensive experience as a Data Engineer, which exceeds the junior level role specified. His skills in Python, SQL, Spark, and AWS align well with the job requirements. However, his seniority and past responsibilities suggest he may be overqualified for a junior position.\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_matches = sorted(matches, key=lambda x: x['match_percentage'], reverse=True)\n",
    "\n",
    "markdown_text = \"\"\"\n",
    "### 📊 Candidate Evaluations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "n = 1\n",
    "for match in sorted_matches:\n",
    "    markdown_text += f\"\"\"**🧑‍💼 Candidate nº{n}: {match['name']} – {match['match_percentage']}%**\n",
    "\n",
    "    {match['summary']}\n",
    "    \n",
    "\"\"\"\n",
    "    n+=1\n",
    "\n",
    "display(Markdown(markdown_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
