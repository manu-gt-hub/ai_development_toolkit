{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0bc5a6-669c-4de4-9c32-17aef875d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils.cv_reviewer_utils as cv_utils\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b93af96-005a-455a-95a6-453cfcba0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Disable SSL warnings (optional but not recommended in production)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3430549e-7dd9-4de9-8d28-ea5163613c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if its published somewhere\n",
    "#job_description = get_job_description(\"url\")\n",
    "\n",
    "job_description = \"\"\"\n",
    "\n",
    "Job Title: Junior Data Engineer\n",
    "Location: Remote\n",
    "Job Type: Full-time\n",
    "Team: Data Engineering\n",
    "Reports to: Senior Data Engineer\n",
    "\n",
    "About the Role:\n",
    "\n",
    "We are looking for a Junior Data Engineer to join our growing data team. You will support the design, development, and maintenance of data pipelines and infrastructure that power data analytics, reporting, and data-driven decision-making across the company.\n",
    "This is a great opportunity for someone early in their career to learn and grow while working on real-world data challenges in a collaborative and agile environment.\n",
    "\n",
    "Key Responsibilities\n",
    "- Assist in building, maintaining, and optimizing ETL/ELT pipelines.\n",
    "- Work closely with data analysts, scientists, and engineers to support data ingestion and transformation workflows.\n",
    "- Help ensure the reliability and quality of data across systems.\n",
    "- Monitor and troubleshoot data pipelines and processes.\n",
    "- Contribute to documentation of data flows, models, and architecture.\n",
    "- Learn and apply best practices in data engineering, including security and scalability.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Basic knowledge of SQL and at least one programming language (Python preferred).\n",
    "- Familiarity with data storage systems (e.g., relational databases, cloud storage).\n",
    "- Understanding of data processing concepts and tools.\n",
    "- Willingness to learn and grow in a fast-paced environment.\n",
    "- Good communication and problem-solving skills.\n",
    "- Bachelor‚Äôs degree in Computer Science, Engineering, Mathematics, or related field (or equivalent practical experience).\n",
    "\n",
    "Nice to Have:\n",
    "\n",
    "- Exposure to cloud platforms like AWS, GCP, or Azure.\n",
    "- Experience with version control (e.g., Git).\n",
    "- Basic knowledge of data modeling concepts.\n",
    "- Familiarity with tools like Airflow, dbt, or Spark.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca89b0d-3f05-4257-a15f-4701ec76d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in lower case\n",
    "mandatory_keywords = [\"spark\",\"python\"]\n",
    "language = \"spanish\"\n",
    "\n",
    "landing_path = './landing'\n",
    "        \n",
    "# \"llama3.2\" or gpt-4o\", \"gpt-4-turbo\", \"gpt-4o-mini\"...\n",
    "model = \"gpt-4-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3556d35-4abc-49fe-bc28-9380a1b7abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Using gpt-4-turbo via OpenAI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Using gpt-4-turbo via OpenAI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Using gpt-4-turbo via OpenAI API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Using gpt-4-turbo via OpenAI API...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üìä Candidate Evaluations\n",
       "\n",
       "\n",
       "**üßë‚Äçüíº Candidate #1: Thaddeus Drake.pdf ‚Äì 85%**\n",
       "\n",
       "El candidato tiene una experiencia relevante en ingenier√≠a de datos, incluyendo el desarrollo y mantenimiento de pipelines de datos en AWS, y la automatizaci√≥n de flujos de trabajo con herramientas como Apache NiFi y Apache Airflow, lo cual coincide con las responsabilidades clave del puesto. Adem√°s, posee un conocimiento s√≥lido en SQL y Python, aline√°ndose con los requisitos t√©cnicos del rol. Sin embargo, no se menciona experiencia directa con GCP o Azure, lo cual podr√≠a ser una √°rea para explorar m√°s.\n",
       "\n",
       "**üìù Recommended Questions**\n",
       "- ¬øPuede describir un desaf√≠o que encontr√≥ al trabajar con pipelines de datos y c√≥mo lo super√≥?\n",
       "- ¬øTiene experiencia trabajando en entornos de desarrollo colaborativos y podr√≠a dar un ejemplo de c√≥mo ha contribuido a la documentaci√≥n de flujos de datos?\n",
       "\n",
       "---\n",
       "\n",
       "**üßë‚Äçüíº Candidate #2: Elara Quinn.pdf ‚Äì 70%**\n",
       "\n",
       "El candidato ha trabajado como pasante de ingenier√≠a de datos, manejando tecnolog√≠as relevantes como Apache Hadoop, MySQL y AWS, que son √∫tiles para el rol ofrecido. Sin embargo, falta experiencia demostrada con Python y herramientas espec√≠ficas como Airflow o Spark, que son deseables seg√∫n la descripci√≥n del trabajo.\n",
       "\n",
       "**üìù Recommended Questions**\n",
       "- ¬øPuede describir una experiencia donde haya tenido que optimizar pipelines de ETL/ELT?\n",
       "- ¬øTiene experiencia con Python en el contexto de la ingenier√≠a de datos? Si es as√≠, ¬øpuede proporcionar un ejemplo espec√≠fico?\n",
       "\n",
       "---\n",
       "\n",
       "**üßë‚Äçüíº Candidate #3: john smith.pdf ‚Äì 65%**\n",
       "\n",
       "El candidato tiene m√°s de 5 a√±os de experiencia trabajando con grandes conjuntos de datos y ha desarrollado bases de datos escalables y procesos ETL, lo que supera el nivel de experiencia t√≠picamente requerido para un puesto de Ingeniero de Datos Junior. Sin embargo, tiene experiencia relevante en tecnolog√≠as clave como SQL y Spark, aunque no se menciona Python, que es preferido para el puesto. Adem√°s, ha trabajado con m√°s de 60 TB de datos diarios, lo que indica una capacidad para manejar grandes vol√∫menes de informaci√≥n.\n",
       "\n",
       "**üìù Recommended Questions**\n",
       "- ¬øPuede describir un proyecto donde haya utilizado SQL para resolver un problema complejo de datos?\n",
       "- Dado que Python es preferido para este rol, ¬øtiene experiencia trabajando con Python en alg√∫n proyecto de datos?\n",
       "- ¬øC√≥mo asegura la calidad y fiabilidad de los datos en los sistemas que desarrolla?\n",
       "\n",
       "---\n",
       "\n",
       "**üßë‚Äçüíº Candidate #4: alan susa.pdf ‚Äì 55%**\n",
       "\n",
       "El candidato tiene experiencia avanzada como Ingeniero de Datos, superando el nivel de entrada requerido para el puesto de Ingeniero de Datos Junior. Ha trabajado con tecnolog√≠as relevantes como Spark, Python, AWS y Airflow, que son compatibles con las mencionadas en la descripci√≥n del trabajo. Sin embargo, su experiencia y habilidades pueden estar por encima del nivel junior, lo que podr√≠a no ser ideal para un rol que busca desarrollar a alguien al principio de su carrera.\n",
       "\n",
       "**üìù Recommended Questions**\n",
       "- ¬øPuede describir un proyecto donde haya tenido que aprender una nueva tecnolog√≠a o herramienta desde cero?\n",
       "- ¬øC√≥mo se ve su rol ideal en t√©rminos de responsabilidades diarias y proyectos a largo plazo?\n",
       "\n",
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_text = cv_utils.analyze_candidates(model, job_description, mandatory_keywords, landing_path, language)\n",
    "display(Markdown(analysis_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
